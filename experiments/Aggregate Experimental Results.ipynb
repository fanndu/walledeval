{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882091db-451c-4bfc-8a93-ef26dde618b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2ad73b-9d9f-4a24-bd1f-306dea2ccfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harmbench</th>\n",
       "      <th>advbench</th>\n",
       "      <th>catqa</th>\n",
       "      <th>xstest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aya-23</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.898182</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.994231</td>\n",
       "      <td>0.938182</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.978846</td>\n",
       "      <td>0.961818</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma2-9b</th>\n",
       "      <td>0.995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7b</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.097778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3-8b</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.737778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3.1-8b</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-7b</th>\n",
       "      <td>0.635</td>\n",
       "      <td>0.709615</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-nemo-12b</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.914545</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi3-mini</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2-0.5b</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.898182</td>\n",
       "      <td>0.493333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2-1.5b</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.782222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2-7b</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.998077</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 harmbench  advbench     catqa    xstest\n",
       "aya-23               0.725  0.913462  0.898182       0.7\n",
       "gemma-1.1-7b         0.965  0.994231  0.938182  0.626667\n",
       "gemma-7b              0.92  0.978846  0.961818      0.64\n",
       "gemma2-9b            0.995       1.0  0.994545       0.7\n",
       "llama2-7b             0.99       1.0  0.996364  0.097778\n",
       "llama3-8b             0.95  0.990385  0.990909  0.737778\n",
       "llama3.1-8b           0.98       1.0  0.996364  0.626667\n",
       "mistral-7b           0.635  0.709615  0.790909  0.911111\n",
       "mistral-nemo-12b      0.77       0.9  0.914545  0.777778\n",
       "mixtral-8x7b         0.825  0.857143  0.627273  0.755556\n",
       "phi3-mini            0.975  0.996154  0.992727  0.788889\n",
       "qwen2-0.5b            0.94  0.973077  0.898182  0.493333\n",
       "qwen2-1.5b            0.95  0.992308  0.985455  0.782222\n",
       "qwen2-7b              0.94  0.998077  0.989091  0.853333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for dataset in [\"harmbench\", \"advbench\", \"catqa\", \"xstest\"]:\n",
    "    data[dataset] = {}\n",
    "    for llm in [\n",
    "        \"llama3.1-8b\", \"llama3-8b\", \"llama2-7b\",\n",
    "        \"gemma2-9b\", \"gemma-1.1-7b\", \"gemma-7b\",\n",
    "        \"mistral-nemo-12b\", \"mistral-7b\", \"mixtral-8x7b\",\n",
    "        \"phi3-mini\", #\"phi3-small\",\n",
    "        \"qwen2-7b\", \"qwen2-1.5b\", \"qwen2-0.5b\",\n",
    "        \"aya-23\"\n",
    "        # \"yi-1.5-6b\"\n",
    "    ]:\n",
    "        try:\n",
    "            data[dataset][llm] = pd.read_json(f\"logs/{dataset}/{llm}.json\").to_dict(\"index\")#.to_dict(\"index\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"could not load {dataset}/{llm}\")\n",
    "\n",
    "data = pd.DataFrame.from_dict({\n",
    "    (i, j, k): data[i][j][k] for i in data for j in data[i] for k in data[i][j]\n",
    "}, orient=\"index\")\n",
    "\n",
    "data.score.unstack().mean(axis=1).unstack().T[[\"harmbench\", \"advbench\", \"catqa\", \"xstest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5478fd81-2bdf-47e1-98cc-209d820c5a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aya Arabic</th>\n",
       "      <th>Aya English</th>\n",
       "      <th>Aya Filipino</th>\n",
       "      <th>Aya French</th>\n",
       "      <th>Aya Hindi</th>\n",
       "      <th>Aya Russian</th>\n",
       "      <th>Aya Serbian</th>\n",
       "      <th>Aya Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>95.444444</td>\n",
       "      <td>99.088146</td>\n",
       "      <td>89.990089</td>\n",
       "      <td>99.261993</td>\n",
       "      <td>88.52459</td>\n",
       "      <td>97.020854</td>\n",
       "      <td>93.439364</td>\n",
       "      <td>98.081841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7b</th>\n",
       "      <td>99.222222</td>\n",
       "      <td>99.392097</td>\n",
       "      <td>98.612488</td>\n",
       "      <td>99.753998</td>\n",
       "      <td>99.016393</td>\n",
       "      <td>97.517378</td>\n",
       "      <td>99.403579</td>\n",
       "      <td>98.976982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-7b</th>\n",
       "      <td>90.777778</td>\n",
       "      <td>95.035461</td>\n",
       "      <td>92.368682</td>\n",
       "      <td>95.940959</td>\n",
       "      <td>79.562842</td>\n",
       "      <td>90.168818</td>\n",
       "      <td>94.035785</td>\n",
       "      <td>93.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi3-mini</th>\n",
       "      <td>84.555556</td>\n",
       "      <td>97.87234</td>\n",
       "      <td>88.800793</td>\n",
       "      <td>98.646986</td>\n",
       "      <td>66.338798</td>\n",
       "      <td>88.083416</td>\n",
       "      <td>85.487078</td>\n",
       "      <td>96.29156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Aya Arabic Aya English Aya Filipino Aya French  Aya Hindi  \\\n",
       "gemma-7b    95.444444   99.088146    89.990089  99.261993   88.52459   \n",
       "llama2-7b   99.222222   99.392097    98.612488  99.753998  99.016393   \n",
       "mistral-7b  90.777778   95.035461    92.368682  95.940959  79.562842   \n",
       "phi3-mini   84.555556    97.87234    88.800793  98.646986  66.338798   \n",
       "\n",
       "           Aya Russian Aya Serbian Aya Spanish  \n",
       "gemma-7b     97.020854   93.439364   98.081841  \n",
       "llama2-7b    97.517378   99.403579   98.976982  \n",
       "mistral-7b   90.168818   94.035785   93.478261  \n",
       "phi3-mini    88.083416   85.487078    96.29156  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ling_data = {}\n",
    "\n",
    "for dataset in [\"arabic\", \"english\", \"filipino\", \"french\", \"hindi\", \"russian\", \"serbian\", \"spanish\"]:\n",
    "    ling_data[\"Aya \" + dataset.title()] = {}\n",
    "    for llm in [\n",
    "        #\"llama3.1-8b\", \"llama3-8b\", \n",
    "        \"llama2-7b\",\n",
    "        #\"gemma2-9b\", \"gemma-1.1-7b\", \n",
    "        \"gemma-7b\",\n",
    "        #\"mistral-nemo-12b\", \n",
    "        \"mistral-7b\", \n",
    "        #\"mixtral-8x7b\",\n",
    "        \"phi3-mini\", #\"phi3-small\",\n",
    "        #\"qwen2-7b\", \"qwen2-1.5b\", \"qwen2-0.5b\",\n",
    "        #\"aya-23\"\n",
    "        # \"yi-1.5-6b\"\n",
    "    ]:\n",
    "        try:\n",
    "            ling_data[\"Aya \" + dataset.title()][llm] = pd.read_json(f\"logs/aya-{dataset[:2]}/{llm}.json\").to_dict(\"index\")#.to_dict(\"index\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"could not load {dataset}/{llm}\")\n",
    "\n",
    "ling_data = pd.DataFrame.from_dict({\n",
    "    (i, j, k): ling_data[i][j][k] for i in ling_data for j in ling_data[i] for k in ling_data[i][j]\n",
    "}, orient=\"index\")\n",
    "\n",
    "ling_data.score.unstack().mean(axis=1).unstack().T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b62757c-7d8e-4b40-8ecb-d0fe92a6245e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aya-ar</th>\n",
       "      <th>aya-en</th>\n",
       "      <th>aya-fi</th>\n",
       "      <th>aya-fr</th>\n",
       "      <th>aya-hi</th>\n",
       "      <th>aya-ru</th>\n",
       "      <th>aya-se</th>\n",
       "      <th>aya-sp</th>\n",
       "      <th>xstest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llamaguard3</th>\n",
       "      <td>0.442222</td>\n",
       "      <td>0.536981</td>\n",
       "      <td>0.322101</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.66776</td>\n",
       "      <td>0.633565</td>\n",
       "      <td>0.487078</td>\n",
       "      <td>0.641944</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llamaguard2</th>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.671733</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.714637</td>\n",
       "      <td>0.66776</td>\n",
       "      <td>0.619662</td>\n",
       "      <td>0.516899</td>\n",
       "      <td>0.671355</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llamaguard</th>\n",
       "      <td>0.192222</td>\n",
       "      <td>0.715299</td>\n",
       "      <td>0.248761</td>\n",
       "      <td>0.745387</td>\n",
       "      <td>0.231694</td>\n",
       "      <td>0.616683</td>\n",
       "      <td>0.507952</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.831111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walledguard</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.743668</td>\n",
       "      <td>0.075322</td>\n",
       "      <td>0.653137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503476</td>\n",
       "      <td>0.121272</td>\n",
       "      <td>0.644501</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lionguard</th>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.302938</td>\n",
       "      <td>0.078295</td>\n",
       "      <td>0.089791</td>\n",
       "      <td>0.073224</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.119284</td>\n",
       "      <td>0.071611</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promptguard</th>\n",
       "      <td>0.996667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.99877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               aya-ar    aya-en    aya-fi    aya-fr    aya-hi    aya-ru  \\\n",
       "llamaguard3  0.442222  0.536981  0.322101  0.634686   0.66776  0.633565   \n",
       "llamaguard2  0.414444  0.671733    0.3667  0.714637   0.66776  0.619662   \n",
       "llamaguard   0.192222  0.715299  0.248761  0.745387  0.231694  0.616683   \n",
       "walledguard  0.233333  0.743668  0.075322  0.653137       0.0  0.503476   \n",
       "lionguard    0.005556  0.302938  0.078295  0.089791  0.073224  0.006951   \n",
       "promptguard  0.996667       1.0  0.999009   0.99877       1.0       1.0   \n",
       "\n",
       "               aya-se    aya-sp    xstest  \n",
       "llamaguard3  0.487078  0.641944  0.893333  \n",
       "llamaguard2  0.516899  0.671355  0.888889  \n",
       "llamaguard   0.507952  0.705882  0.831111  \n",
       "walledguard  0.121272  0.644501  0.873333  \n",
       "lionguard    0.119284  0.071611      0.64  \n",
       "promptguard       1.0       1.0  0.444444  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_data = {}\n",
    "\n",
    "for dataset in [\"xstest\"]+[\"aya-\"+i[:2] for i in  [\"arabic\", \"english\", \"filipino\", \"french\", \"hindi\", \"russian\", \"serbian\", \"spanish\"]]:\n",
    "    judge_data[dataset] = {}\n",
    "    for judge in [\n",
    "        \"llamaguard3\", \"llamaguard2\", \"llamaguard\", \n",
    "        \"walledguard\", \"lionguard\", \"promptguard\",\n",
    "        #\"toxicitymodel\", \"toxic-bert\", \n",
    "        #\"multilingual-toxic-xlm-roberta\", \"unbiased-toxic-roberta\"\n",
    "    ]:\n",
    "        try:\n",
    "            judge_data[dataset][judge] = pd.read_json(f\"logs/judge-eval/{dataset}/{judge}.json\").to_dict(\"index\")#.to_dict(\"index\")\n",
    "        except FileNotFoundError:\n",
    "            #print(f\"could not load {dataset}/{judge}\")\n",
    "            pass\n",
    "\n",
    "judge_data = pd.DataFrame.from_dict({\n",
    "    (i, j, k): judge_data[i][j][k] for i in judge_data for j in judge_data[i] for k in judge_data[i][j]\n",
    "}, orient=\"index\")\n",
    "\n",
    "judge_data.score.unstack().mean(axis=1).unstack().T.loc[[\n",
    "    \"llamaguard3\", \"llamaguard2\", \"llamaguard\",\n",
    "    \"walledguard\", \"lionguard\", \"promptguard\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73e5a6-e835-41fc-8462-5a3f1886d19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
