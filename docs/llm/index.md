# LLMs (`walledeval.llm`)

WalledEval's LLM architecture aims to support various kinds of LLMs, which a current focus on Decoder-only and MoE architecures. These LLMs are used as **systems-under-test (SUTs)**, which allows generating question answers and prompt outputs.

