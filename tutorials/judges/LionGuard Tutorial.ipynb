{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5202b9c7-562d-4c56-9a4d-fa2bb19b256c",
   "metadata": {},
   "source": [
    "# LionGuard\n",
    "\n",
    "LionGuard is a classifier for detecting unsafe content in the Singaporean context. It uses [pre-trained BAAI English embeddings](https://huggingface.co/BAAI/bge-large-en-v1.5) and performs classification with a trained classification model. The [original beta version](https://huggingface.co/jfooyh/lionguard-beta) uses an XGBoost classifier, whereas the [new LionGuard models](https://huggingface.co/dsaidgovsg) released by DSAID GovTech use a Ridge classifier.\n",
    "\n",
    "<small><i>GovTech introduced LionGuard [on 24th June at a technical sharing session](https://www.imda.gov.sg/activities/activities-catalogue/technical-sharing-session-on-ai-robustness). The above description has been modified from the [LionGuard-binary model release](https://huggingface.co/dsaidgovsg/lionguard-binary-v1.0).</i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6f4fa0-4b80-4e98-8a9b-44eea583ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d3f22-3ae5-4195-a3e5-c2396675d625",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99f6d5f-51f5-4429-b107-db2d1231c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from walledeval.judge import LionGuardJudge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f82755-bf49-42d0-bc25-fa0e93059dfc",
   "metadata": {},
   "source": [
    "The [LionGuard-binary](https://huggingface.co/dsaidgovsg/lionguard-binary-v1.0) model is a Ridge classifier that embeds the input text based on the [BAAI English embeddings model](https://huggingface.co/BAAI/bge-large-en-v1.5) and inputs said embeddings into the pretrained classifier. Our system uses presets to load any of the models released by LionGuard's team.\n",
    "\n",
    "These are the models supported:\n",
    "\n",
    "|Model|Classifier Type|Preset|\n",
    "|:--------------------------------------------------------------:|:-------:|:------:|\n",
    "| [LionGuard-beta](https://huggingface.co/jfooyh/lionguard-beta) | XGBoost | `beta` |\n",
    "| [LionGuard-binary-v1.0](https://huggingface.co/dsaidgovsg/lionguard-binary-v1.0 ) | Ridge | `binary` |\n",
    "| [LionGuard-harassment-v1.0](https://huggingface.co/dsaidgovsg/lionguard-harassment-v1.0) | Ridge | `harassment` | \n",
    "| [LionGuard-hateful-v1.0](https://huggingface.co/dsaidgovsg/lionguard-hateful-v1.0) | Ridge | `hateful` |\n",
    "| [LionGuard-public_harm-v1.0](https://huggingface.co/dsaidgovsg/lionguard-public_harm-v1.0) | Ridge | `public_harm` |\n",
    "| [LionGuard-self_harm-v1.0](https://huggingface.co/dsaidgovsg/lionguard-self_harm-v1.0) | Ridge | `self_harm` |\n",
    "| [LionGuard-sexual-v1.0](https://huggingface.co/dsaidgovsg/lionguard-sexual-v1.0) | Ridge | `sexual` |\n",
    "| [LionGuard-toxic-v1.0](https://huggingface.co/dsaidgovsg/lionguard-toxic-v1.0 ) | Ridge | `toxic` |\n",
    " |[LionGuard-violent-v1.0](https://huggingface.co/dsaidgovsg/lionguard-violent-v1.0) | Ridge | `violent` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4ef989-f529-4f82-bea4-00056700e262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<walledeval.judge.lionguard.LionGuardJudge at 0x7f1ba6abcd90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = LionGuardJudge.from_preset(\"binary\")\n",
    "binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24d555-9e36-42cd-a490-e0584964bfd6",
   "metadata": {},
   "source": [
    "The `embed` function is an intermediary function used to format embeddings based on the BBAI English Embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f131af-66c1-431c-98e8-40286280b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0343454 ,  0.03316101,  0.02191255, ..., -0.00717639,\n",
       "        -0.00188533,  0.01511723]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.embed(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc098da7-c6c5-417c-87c0-8d3976d09ccb",
   "metadata": {},
   "source": [
    "The `check` function is the default function in our judges, which takes in the text and outputs a logit. The logit value is a value between 0 and 1 and shows how toxic the text is (1 being \"most toxic\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76823a20-0b69-447b-95c8-859bec7332a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030662020668387413"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e449ced-b954-4e76-8e8a-a2d202c28e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"bloody fuck you bloody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd9a8dc-4c6b-4de4-ba62-7cb771ca407a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2818181812763214"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00de7aa2-3643-49e6-931c-485ec3c8e221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09012345969676971"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"chibai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaf15e8-88df-43b5-ad43-bf0400b28fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28015562891960144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"knn chao chibai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f01222-ba7c-4adb-ad49-859f4bc842d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.score(0.28015562891960144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a47a673-ff2a-4cae-b17d-2b4b6efe263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 0.28015562891960144\n",
      "Classification: safe\n"
     ]
    }
   ],
   "source": [
    "output, score = binary(\"knn chao chibai\")\n",
    "print(\"Output:\", output)\n",
    "print(\"Classification:\", \"safe\" if score else \"unsafe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71903c-d16c-4e0b-bf19-fd87bdc539ef",
   "metadata": {},
   "source": [
    "The above results show that the model is well-finetuned on english words like \"fuck\", but funnily enough, a chinese swear word like \"knn\" isn't strongly recognized, and another like \"chibai\" isn't even classified positively. This shows that the model is not very good at classifying toxic Singaporean phrases, which is rather ironic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1b3d5-1050-4f32-a200-4b2ffc614dae",
   "metadata": {},
   "source": [
    "## Testing the Beta Model\n",
    "\n",
    "The Beta model is different because it is a XGBoost classiifer. Hence, here's another demo (similar to above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a3a393a-b3ac-415b-9dae-c02393d4f6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<walledeval.judge.lionguard.LionGuardJudge at 0x7f1addcbfca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = LionGuardJudge.from_preset(\"beta\")\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed0b82a-c99b-4370-a7a6-46b959ae24e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0343454 ,  0.03316101,  0.02191255, ..., -0.00717639,\n",
       "        -0.00188533,  0.01511723]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.embed(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0c4494-0efd-4622-8ea5-af497a707cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.457677565980703e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7382c9dc-70bc-46e2-8d3e-62a3613f6c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999995231628418"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"bloody fuck you bloody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611354f6-c9c2-424a-820a-761d63617811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999834418296814"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ffb8dab-1405-4f15-a9de-384d5cec1eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005032883491367102"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"chibai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "394439b5-0a5d-4f48-ae39-6eb6dfee552c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807035684585571"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"knn chao chibai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e04f569-6612-41fe-be39-a000a2849eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.score(0.8807035684585571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d9a91fd-737c-4f5b-90f3-04b956ef2ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 0.8807035684585571\n",
      "Classification: unsafe\n"
     ]
    }
   ],
   "source": [
    "output, score = beta(\"knn chao chibai\")\n",
    "print(\"Output:\", output)\n",
    "print(\"Classification:\", \"safe\" if score else \"unsafe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a849a-ae40-476d-b35b-9cfa0e572a19",
   "metadata": {},
   "source": [
    "Even here, it acts pretty similarly, but is able to identify a word like \"knn\" is pretty bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
