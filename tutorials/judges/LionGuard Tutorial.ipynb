{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5202b9c7-562d-4c56-9a4d-fa2bb19b256c",
   "metadata": {},
   "source": [
    "# LionGuard\n",
    "\n",
    "LionGuard is a classifier for detecting unsafe content in the Singaporean context. It uses [pre-trained BAAI English embeddings](https://huggingface.co/BAAI/bge-large-en-v1.5) and performs classification with a trained classification model. The [original beta version](https://huggingface.co/jfooyh/lionguard-beta) uses an XGBoost classifier, whereas the [new LionGuard models](https://huggingface.co/dsaidgovsg) released by DSAID GovTech use a Ridge classifier.\n",
    "\n",
    "<small><i>GovTech introduced LionGuard [on 24th June at a technical sharing session](https://www.imda.gov.sg/activities/activities-catalogue/technical-sharing-session-on-ai-robustness). The above description has been modified from the [LionGuard-binary model release](https://huggingface.co/dsaidgovsg/lionguard-binary-v1.0).</i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6f4fa0-4b80-4e98-8a9b-44eea583ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d3f22-3ae5-4195-a3e5-c2396675d625",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99f6d5f-51f5-4429-b107-db2d1231c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from walledeval.judge import LionGuardJudge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb24c8e-6a3d-47bc-b100-2e6d77b9a61a",
   "metadata": {},
   "source": [
    "The [LionGuard-binary](https://huggingface.co/dsaidgovsg/lionguard-binary-v1.0) model is a Ridge classifier that embeds the input text based on the [BAAI English embeddings model](https://huggingface.co/BAAI/bge-large-en-v1.5) and inputs said embeddings into the pretrained classifier. Our system uses presets to load any of the models released by LionGuard's team.\n",
    "\n",
    "These are the models supported:\n",
    "\n",
    "|Model|Classifier Type|Preset|\n",
    "|--------------------------------------------------------------------------------------------|--------|--------------|\n",
    "| [LionGuard-beta](https://huggingface.co/jfooyh/lionguard-beta) | XGBoost | `beta` |\r\n",
    " |[LionGuard-binary-v1.0](https://huggingface.co/dsaidgovsg/lionguard-binary-v1.0 ) |Ridg e `binary` ||\r",
    " \n",
    "|[LionGuard-harassment-v1.0](https://huggingface.co/dsaidgovsg/lionguard-harassment-v1. 0 )|Rid g `harassment` |e| \r\n",
    "|[LionGuard-hateful-v1.0](https://huggingface.co/dsaidgovsg/lionguard-hateful-v1 . 0)|Ri d `hateful` |ge |\r\n",
    "|[LionGuard-public_harm-v1.0](https://huggingface.co/dsaidgovsg/lionguard-public_harm-v 1 .0)|R i `public_harm` |dg e|\r\n",
    "|[LionGuard-self_harm-v1.0](https://huggingface.co/dsaidgovsg/lionguard-self_harm- v 1.0)| R `self_harm` |id ge|\r\n",
    "|[LionGuard-sexual-v1.0](https://huggingface.co/dsaidgovsg/lionguard-sexual - v1.0) | `sexual` |Ri dge|\r\n",
    "|[LionGuard-toxic-v1.0](https://huggingface.co/dsaidgovsg/lionguard-toxi c -v1.0 ) `toxic` ||R idge|\r\n",
    "|[LionGuard-violent-v1.0](https://huggingface.co/dsaidgovsg/lionguard-viole n t-v1. 0 `violent` |)|Ridge|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4ef989-f529-4f82-bea4-00056700e262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<walledeval.judge.lionguard.LionGuardJudge at 0x7fe07488c880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = LionGuardJudge.from_preset(\"binary\")\n",
    "binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24d555-9e36-42cd-a490-e0584964bfd6",
   "metadata": {},
   "source": [
    "The `embed` function is an intermediary function used to format embeddings based on the BBAI English Embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f131af-66c1-431c-98e8-40286280b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0343454 ,  0.03316101,  0.02191255, ..., -0.00717639,\n",
       "        -0.00188533,  0.01511723]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.embed(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc098da7-c6c5-417c-87c0-8d3976d09ccb",
   "metadata": {},
   "source": [
    "The `check` function is the default function in our judges, which takes in the text and outputs a logit. The logit value is a value between 0 and 1 and shows how toxic the text is (1 being \"most toxic\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76823a20-0b69-447b-95c8-859bec7332a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07944314947105535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e449ced-b954-4e76-8e8a-a2d202c28e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448972910301721"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"bloody fuck you bloody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd9a8dc-4c6b-4de4-ba62-7cb771ca407a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6833139548316369"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00de7aa2-3643-49e6-931c-485ec3c8e221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4251215203228169"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"chibai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaf15e8-88df-43b5-ad43-bf0400b28fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7664647232486067"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"knn chao chibai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71903c-d16c-4e0b-bf19-fd87bdc539ef",
   "metadata": {},
   "source": [
    "The above results show that the model is well-finetuned on english words like \"fuck\", but funnily enough, a chinese swear word like \"knn\" isn't strongly recognized, and another liek \"chibai\" isn't even classified positively. This shows that the model is not very good at classifying toxic Singaporean phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1b3d5-1050-4f32-a200-4b2ffc614dae",
   "metadata": {},
   "source": [
    "## Testing the Beta Model\n",
    "\n",
    "The Beta model is different because it is a XGBoost classiifer. Hence, here's another demo (similar to above of LionGuard-Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3a393a-b3ac-415b-9dae-c02393d4f6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<walledeval.judge.lionguard.LionGuardJudge at 0x7fe072ea1d80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = LionGuardJudge.from_preset(\"beta\")\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed0b82a-c99b-4370-a7a6-46b959ae24e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0343454 ,  0.03316101,  0.02191255, ..., -0.00717639,\n",
       "        -0.00188533,  0.01511723]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.embed(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e0c4494-0efd-4622-8ea5-af497a707cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.457677565980703e-05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7382c9dc-70bc-46e2-8d3e-62a3613f6c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999995231628418"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"bloody fuck you bloody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "611354f6-c9c2-424a-820a-761d63617811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999834418296814"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ffb8dab-1405-4f15-a9de-384d5cec1eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4251215203228169"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.check(\"chibai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "394439b5-0a5d-4f48-ae39-6eb6dfee552c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807035684585571"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.check(\"knn chao chibai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a849a-ae40-476d-b35b-9cfa0e572a19",
   "metadata": {},
   "source": [
    "Even here, it acts pretty similarly, but is able to identify a word like \"knn\" is pretty bad!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
